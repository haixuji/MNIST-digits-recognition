# -*- coding: utf-8 -*-
"""245 project code

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16pEbrsf5gS6M8RSx8yhPnPCGDexLgBDY
"""

import numpy as np

from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from sklearn.svm import SVC


class MNIST_SVM(object):
    def __init__(self):
        self.load_mnist()

    def load_mnist(self):
        from sklearn import datasets
        from sklearn.model_selection import train_test_split

        digits = datasets.load_digits()

        # flatten the images
        n_samples = len(digits.images)
        data = digits.images.reshape((n_samples, -1))
        label = digits.target

        # Split data into 80% train and 20% test subsets
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(data, label,  #digits.target,
                                                                                test_size=0.2, shuffle=False)

    def train(self):
        # Create a classifier: a support vector classifier
        self.clf = SVC(gamma=0.001)

        # Learn the digits on the train subset
        self.clf.fit(self.X_train, self.y_train)

        # Predict the value of the digit on the test subset
        predicted = self.clf.predict(self.X_test)
        self.performance(self.y_test, predicted)

    def performance(self, y_test, y_predict):
        from sklearn.metrics import classification_report, confusion_matrix
        import pandas as pd

        report = classification_report(y_test, y_predict)
        print(report)


def test():
    # SVM
    prj = MNIST_SVM()
    prj.train()


if __name__ == '__main__':
    test()

    exit(0)

import numpy as np

from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from sklearn.svm import SVC

from sklearn.neighbors import KNeighborsClassifier
!pip3 install Pillow scikit-learn python-mnist

class MNIST_KNN(object):
    def __init__(self):
        self.load_mnist()

    def load_mnist(self):
        """
        Note that python-mnist and mnist are two different packages, and they
        both have a module called mnist. The package you want is python-mnist.
        So do this:
        pip install python-mnist
        It might be necessary to uninstall the mnist package with:
        pip uninstall mnist
        Then your import statement should work.
        """
        from mnist import MNIST

        mndata = MNIST()
        self.images_train, self.labels_train = mndata.load_training()
        self.images_test, self.labels_test = mndata.load_testing()

    def train(self):
        # Create a classifier: a KNN classifier
        self.clf = KNeighborsClassifier()

        # Learn the digits on the train subset
        self.clf.fit(self.images_train, self.labels_train)

        # Predict the value of the digit on the test subset
        predicted = self.clf.predict(self.images_test)

        # tolist()!!!
        self.performance(self.labels_test.tolist(), predicted)

    def performance(self, y_test, y_predict):
        from sklearn.metrics import classification_report, confusion_matrix
        import pandas as pd

        report = classification_report(y_test, y_predict)
        print(report)


def test():
    # KNN
    prj = MNIST_KNN()
    prj.train()


if __name__ == '__main__':
    test()

    exit(0)

import numpy as np

from sklearn.linear_model import LogisticRegression
from matplotlib import pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from numpy import mean
from numpy import std
from matplotlib import pyplot
from sklearn.model_selection import KFold
from keras.datasets import mnist
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.layers import BatchNormalization


class MNIST_CNN(object):
    def __init__(self):
        self.load_mnist()

        # prepare pixel data
        self.trainX, self.testX = self.prep_pixels(self.trainX, self.testX)

    def load_mnist(self):
        """
        load train and test dataset
        """
        # load dataset
        (self.trainX, self.trainY), (self.testX, self.testY0) = mnist.load_data()

        # reshape dataset to have a single channel
        self.trainX = self.trainX.reshape((self.trainX.shape[0], 28, 28, 1))

        self.testX = self.testX.reshape((self.testX.shape[0], 28, 28, 1))

        # one hot encode target values
        self.trainY = to_categorical(self.trainY)
        self.testY = to_categorical(self.testY0)

    def prep_pixels(self, train_set, test_set):
        """
        Scale pixels
        :param train_set:
        :param test_set:
        :return:
        """
        # convert from integers to floats
        train_norm = train_set.astype('float32')
        test_norm = test_set.astype('float32')

        # normalize to range 0-1
        train_norm = train_norm / 255.0
        test_norm = test_norm / 255.0

        # return normalized images
        return train_norm, test_norm

    def define_model(self):
        """
        define cnn model
        :return:
        """
        model = Sequential()
        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))
        model.add(BatchNormalization())     # Improvement to Learning
        model.add(MaxPooling2D((2, 2)))
        model.add(Flatten())
        model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))
        model.add(BatchNormalization())     # Improvement to Learning
        model.add(Dense(10, activation='softmax'))

        # compile model
        opt = SGD(lr=0.01, momentum=0.9)
        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
        return model

    def train(self, epochs=10):
        # define model
        model = self.define_model()

        # fit model
        history = model.fit(self.trainX, self.trainY,
                            epochs=epochs,
                            batch_size=32,
                            validation_data=(self.testX, self.testY),
                            verbose=0)

        # evaluate model
        loss, acc = model.evaluate(self.testX, self.testY, verbose=0)
        print('> %.4e %.3f' % (loss, acc * 100.0))

        #y_prob = model.predict(self.testX, batch_size=1)
        #print(y_prob)

        y_pred = model.predict_classes(self.testX, batch_size=1)
        #print(y_pred)

        #print(self.testY0)
        self.performance(self.testY0, y_pred)

    def performance(self, y_test, y_predict):
        from sklearn.metrics import classification_report, confusion_matrix
        import pandas as pd

        report = classification_report(y_test, y_predict)
        print(report)


def test():
    # CNN
    prj = MNIST_CNN()
    prj.train(epochs=5)   


if __name__ == '__main__':
    test()

    exit(0)